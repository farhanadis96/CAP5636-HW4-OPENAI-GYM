{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cart Pole Policy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Definition\n",
    "State 0 represents the position of the cart. When cart moves to the extreme right side, the policy implemented will pull the cart towards the left to ensure the episode does not terminate quickly and vice versa. States 2 and 3 represent the angle of the pole it makes with the cart and the velocity of the cart respectively. In this policy, if the angle of the pole and the velocity of the cart is greater than 0, then the policy pushes the cart to the right otherwise the policy pushes the cart to the left to ensure the pole is maintained in an upright position through out the episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state):\n",
    "   \n",
    "    if (state[0] < -1.8):\n",
    "        return 1\n",
    "    \n",
    "    if (state[0] > 1.8):\n",
    "        return 0\n",
    "    \n",
    "    if(state[3]>0 and state[2]>0 ):\n",
    "\n",
    "        return 1\n",
    "    \n",
    "    if (state[3] < 0 and state[2] < 0):\n",
    "        return 0\n",
    "    return env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewards collected : [200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200. 200.\n",
      " 200. 200. 200. 200. 200. 200.]\n",
      "Maximum  200.0 Minimum  200.0 Mean  200.0\n"
     ]
    }
   ],
   "source": [
    "reward_total=[]\n",
    "for i_episode in range(20):\n",
    "    state = env.reset()\n",
    "\n",
    "    count=0\n",
    "    for t in range(200):\n",
    "        env.render()\n",
    "        \n",
    "        \n",
    "        action=policy(state)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        count=count+reward\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "\n",
    "            break\n",
    "    reward_total.append(count)\n",
    "\n",
    "reward_total=np.array(reward_total)\n",
    "print(\"Rewards collected :\",reward_total)\n",
    "print(\"Maximum \",np.max(reward_total),\"Minimum \" ,np.min(reward_total),\"Mean \" ,np.mean(reward_total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
